{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "604a4ed7-8ada-4f2e-8bff-e725c46ba627",
   "metadata": {},
   "source": [
    "https://ladsweb.modaps.eosdis.nasa.gov/api/v2/content/archives/Document%20Archive/Science%20Data%20Product%20Documentation/VIIRS_Black_Marble_UG_v1.1_July_2020.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f86e0a41-fde9-45fc-bcd3-45e9c91842d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "from rasterio.merge import merge\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio.mask\n",
    "import rasterio as rio\n",
    "import datetime as dt\n",
    "from datetime import date\n",
    "import subprocess\n",
    "import matplotlib.dates as mdates\n",
    "from unittest import result\n",
    "import fiona\n",
    "import itertools\n",
    "\n",
    "BASE_PATH = \"/home/ethan/blackmarble/\"\n",
    "\n",
    "RAW_H5 = glob.glob(f'{BASE_PATH}raw/**.h5')\n",
    "RAW_H5.sort()\n",
    "\n",
    "dates = {}\n",
    "\n",
    "def buildInitialTifs():\n",
    "\n",
    "    # Unpack h5 files and sort into ntl data and quality masks (ntl_tifs and quality_tifs, respectively)\n",
    "    for file in RAW_H5:   \n",
    "\n",
    "        hdflayer = gdal.Open(file, gdal.GA_ReadOnly) # Initiate opening of HDF5 file\n",
    "\n",
    "        subhdflayer = hdflayer.GetSubDatasets()[2][0] # Read the Gap_Filled_DNB_BRDF-Corrected_NTL field\n",
    "        rlayer = gdal.Open(subhdflayer, gdal.GA_ReadOnly) # Load NTL data into rlayer\n",
    "\n",
    "        qualitylayer = hdflayer.GetSubDatasets()[4][0] # Read the Mandatory_Quality_Flag field\n",
    "        qlayer = gdal.Open(qualitylayer, gdal.GA_ReadOnly) # Load quality layer data into qlayer\n",
    "\n",
    "        # TODO\n",
    "        output_name = str(file).split('/')[5]\n",
    "        quality_output_name = str(file).split('/')[5] + ' Quality'\n",
    "        # TODO\n",
    "\n",
    "        HorizontalTileNumber = int(rlayer.GetMetadata_Dict()[\"HorizontalTileNumber\"])\n",
    "        VerticalTileNumber = int(rlayer.GetMetadata_Dict()[\"VerticalTileNumber\"])\n",
    "        WestBoundCoord = (10*HorizontalTileNumber) - 180\n",
    "        NorthBoundCoord = 90-(10*VerticalTileNumber)\n",
    "        EastBoundCoord = WestBoundCoord + 10\n",
    "        SouthBoundCoord = NorthBoundCoord - 10\n",
    "\n",
    "        EPSG = \"-a_srs EPSG:4326\" #WGS84\n",
    "\n",
    "        translateOptionText = EPSG +\" -a_ullr \" + str(WestBoundCoord) + \" \" + str(NorthBoundCoord) + \" \" + str(EastBoundCoord) + \" \" + str(SouthBoundCoord)\n",
    "\n",
    "        translateoptions = gdal.TranslateOptions(gdal.ParseCommandLine(translateOptionText))\n",
    "        gdal.Translate(f'{BASE_PATH}output/ntl_tifs/' + output_name + '.tif', rlayer, options = translateoptions)\n",
    "        gdal.Translate(f'{BASE_PATH}output/quality_tifs/' + quality_output_name + '.tif', qlayer, options = translateoptions)\n",
    "    \n",
    "    # Create list of all ntl tifs and quality tifs\n",
    "    all_tifs = glob.glob(f'{BASE_PATH}output/ntl_tifs/**.tif').extend(glob.glob(f'{BASE_PATH}output/quality_tifs/**.tif'))\n",
    "\n",
    "    # Sort alphabetically for cleanliness' sake\n",
    "    all_tifs.sort()\n",
    "\n",
    "    # /Volumes/Sandisk/BlackMarble/Merged Tiles\n",
    "    for file in all_tifs:\n",
    "    \n",
    "        output_name = file.split('/')[5]\n",
    "\n",
    "        with fiona.open(f\"{BASE_PATH}shapes/dallas_shp/dallas_shp.shp\") as shapefile:\n",
    "            shapes = [feature[\"geometry\"] for feature in shapefile]\n",
    "\n",
    "        with rio.open(file) as src:\n",
    "            out_image, out_transform = rio.mask.mask(src, shapes, nodata=65535, crop=True)\n",
    "            out_meta = src.meta\n",
    "            out_meta.update({\"driver\": \"GTiff\",\n",
    "                 \"height\": out_image.shape[1],\n",
    "                 \"width\": out_image.shape[2],\n",
    "                 \"transform\": out_transform})\n",
    "\n",
    "        if 'Quality' in output_name:\n",
    "            with rio.open(f'{BASE_PATH}output/quality_tifs/' + str(output_name), \"w\", **out_meta) as dest:\n",
    "                dest.write(out_image)\n",
    "\n",
    "        else:\n",
    "            with rio.open(f'{BASE_PATH}output/ntl_tifs/' + str(output_name), \"w\", **out_meta) as dest:\n",
    "                dest.write(out_image)\n",
    "        \n",
    "        # Delete the merged file once it has been used to generate the NTL and Quality files covering the Korean Peninsula\n",
    "        os.remove(file)\n",
    "                \n",
    "    print('Initial tifs created.')\n",
    "\n",
    "def createUnmaskedTifsAndPngs():\n",
    "\n",
    "    # /Volumes/Sandisk/BlackMarble/DPRK Only/quality_masks/\n",
    "    ntl_tifs = glob.glob(f'{BASE_PATH}output/ntl_tifs/**.tif')\n",
    "\n",
    "    for ntl in ntl_tifs:\n",
    "\n",
    "        # TODO\n",
    "        output_name = str(ntl).split('/')[6]\n",
    "        # TODO\n",
    "\n",
    "        ntl = gdal.Open(ntl)\n",
    "\n",
    "        ntl_meta = ntl.GetMetadata()                   # Store metadata in dictionary\n",
    "        ntl_rows, ntl_cols = ntl.RasterYSize, ntl.RasterXSize  # Number of rows,columns\n",
    "        ntl_geotransform = ntl.GetGeoTransform()\n",
    "        ntl_proj = ntl.GetProjection()\n",
    "\n",
    "        NTLBand = ntl.GetRasterBand(1)\n",
    "        NTLData = NTLBand.ReadAsArray().astype(\n",
    "            'float')  # Data for export as unamsked tif\n",
    "        NTLData *= 0.1  # Apply scale per BlackMarble documentation\n",
    "\n",
    "        unmasked_outpath = f'{BASE_PATH}output/dallas_no_mask/'\n",
    "\n",
    "        os.chdir(unmasked_outpath)\n",
    "        # Select GDAL GeoTIFF driver\n",
    "        driver = gdal.GetDriverByName('GTiff')\n",
    "        # Specify the parameters of the GeoTIFF\n",
    "        outfile = driver.Create(output_name, ntl_cols,\n",
    "                                ntl_rows, 1, gdal.GDT_Float32)\n",
    "        # Set Geotransform\n",
    "        outfile.SetGeoTransform(ntl_geotransform)\n",
    "        # Get band 1\n",
    "        band = outfile.GetRasterBand(1)\n",
    "        # Write the array to band 1\n",
    "        band.WriteArray(NTLData)\n",
    "        # Set projection\n",
    "        outfile.SetProjection(ntl_proj)\n",
    "        # Export data\n",
    "        band.FlushCache()\n",
    "        # Set fill value\n",
    "        band.SetNoDataValue(65535)\n",
    "        # Close ntl_tifs[i]\n",
    "        outfile = None\n",
    "\n",
    "        ntl = None\n",
    "        mask = None\n",
    "\n",
    "    print('Unmasked tifs created.')\n",
    "\n",
    "def createMaskedTifsAndPngs():\n",
    "\n",
    "    masks = glob.glob(\n",
    "        f'{BASE_PATH}output/quality_tifs/**.tif')\n",
    "    ntl_tifs = glob.glob(\n",
    "        f'{BASE_PATH}output/ntl_tifs/**.tif')\n",
    "    \n",
    "    masks.sort()  # Ensure masks and ntl data sets line up for processing\n",
    "    ntl_tifs.sort()  # Ensure masks and ntl data sets line up for processing\n",
    "\n",
    "    for mask, ntl in zip(masks, ntl_tifs):\n",
    "        output_name = str(ntl).split('/')[6]\n",
    "        mask = gdal.Open(mask)\n",
    "        ntl = gdal.Open(ntl)\n",
    "\n",
    "        ntl_meta = ntl.GetMetadata()                   # Store metadata in dictionary\n",
    "        ntl_rows, ntl_cols = ntl.RasterYSize, ntl.RasterXSize  # Number of rows,columns\n",
    "        ntl_geotransform = ntl.GetGeoTransform()\n",
    "        ntl_proj = ntl.GetProjection()\n",
    "\n",
    "        mask_meta = mask.GetMetadata()                   # Store metadata in dictionary\n",
    "        mask_rows, mask_cols = mask.RasterYSize, mask.RasterXSize  # Number of rows,columns\n",
    "        mask_geotransform = mask.GetGeoTransform()\n",
    "        mask_proj = mask.GetProjection()\n",
    "\n",
    "        NTLBand = ntl.GetRasterBand(1)\n",
    "        NTLData = NTLBand.ReadAsArray().astype(\n",
    "            'float')  # Data for export as unamsked tif\n",
    "        NTLData *= 0.1  # Apply scale per BlackMarble documentation\n",
    "\n",
    "        MASKBand = mask.GetRasterBand(1)\n",
    "        MaskData = MASKBand.ReadAsArray().astype('float')\n",
    "        # Mask array, only include high-quality bits, for export to tif\n",
    "        MASKED_NTL = np.ma.MaskedArray(\n",
    "            NTLData, np.in1d(MaskData, [0, 1], invert=False))\n",
    "\n",
    "        masked_outpath = f'{BASE_PATH}output/dallas_mask/'\n",
    "\n",
    "        os.chdir(masked_outpath)\n",
    "        # Split mask from data\n",
    "        MASKED_NTL.unshare_mask()\n",
    "        # Set masked values equal to fill value\n",
    "        MASKED_NTL[MASKED_NTL.mask == True] = 65535\n",
    "        # Select GDAL GeoTIFF driver\n",
    "        driver = gdal.GetDriverByName('GTiff')\n",
    "        # Specify the parameters of the GeoTIFF\n",
    "        outfile = driver.Create(output_name, ntl_cols,\n",
    "                                ntl_rows, 1, gdal.GDT_Float32)\n",
    "        # Set Geotransform\n",
    "        outfile.SetGeoTransform(ntl_geotransform)\n",
    "        # Get band 1\n",
    "        band = outfile.GetRasterBand(1)\n",
    "        # Write the array to band 1\n",
    "        band.WriteArray(MASKED_NTL)\n",
    "\n",
    "        # Set projection\n",
    "        outfile.SetProjection(ntl_proj)\n",
    "        # Export data\n",
    "        band.FlushCache()\n",
    "        # Set fill value\n",
    "        band.SetNoDataValue(65535)\n",
    "        # Close file\n",
    "        outfile = None\n",
    "\n",
    "        ntl = None\n",
    "        mask = None\n",
    "\n",
    "    print('Masked tifs created.')\n",
    "\n",
    "# Helper functions for creating charts\n",
    "\n",
    "def createRasterData(raster):\n",
    "    ntl = gdal.Open(raster)\n",
    "    NTLBand = ntl.GetRasterBand(1)\n",
    "    NTLData = NTLBand.ReadAsArray()\n",
    "    return NTLData\n",
    "\n",
    "def createDateRange(start, end):\n",
    "    startdate = dt.datetime.strptime(start, '%m/%d/%Y').date().strftime('%Y%j')\n",
    "    enddate = dt.datetime.strptime(end, '%m/%d/%Y').date().strftime('%Y%j')\n",
    "    dateranges = list(np.arange(int(startdate), int(enddate)))\n",
    "    tif_names = []\n",
    "\n",
    "    for d in dateranges:\n",
    "        d = 'A' + str(d) + '.tif'\n",
    "        tif_names.append(d)\n",
    "\n",
    "    return tif_names\n",
    "\n",
    "def calcValidPixels(province):\n",
    "    # Obtain the raster data of an unmasked dallas tif -- we will count the number of pixels in the raster\n",
    "    raster_data = np.array(createRasterData(f\"{BASE_PATH}output/dallas_no_mask/A2020275.tif\")).flatten()\n",
    "    raster_data[raster_data == 65535] = np.nan\n",
    "    total_pixels = np.count_nonzero(~np.isnan(raster_data))\n",
    "    return total_pixels\n",
    "\n",
    "def generate_date_list(): # Used to update global variable DATES when new files are added to the RAW working directory\n",
    "\n",
    "    result_array = []\n",
    "    \n",
    "    for file in RAW_H5:\n",
    "        title = file.split('/')[5].split('.')[1]\n",
    "        yyyyddd = title[1:8]                                          # First: product name\n",
    "        date = dt.datetime.strptime(yyyyddd, '%Y%j').strftime('%m/%d/%Y')              # Convert YYYYDDD to MM/DD/YYYY\n",
    "        result_array.append(date)\n",
    "        \n",
    "    return result_array\n",
    "\n",
    "def showTif(specific_file):\n",
    "    file = gdal.Open(specific_file)\n",
    "    band = file.GetRasterBand(1)\n",
    "    data = band.ReadAsArray().astype('float') # Import band as an array with type float\n",
    "    print(np.nanmax(data))\n",
    "    \n",
    "    plt.figure(figsize = (10,7.5))    # Set the figure size (x,y)\n",
    "    plt.axis('off')                   # Remove the axes' values\n",
    "    # Plot the array, using a colormap and setting a custom linear stretch based on the min/max EVI values\n",
    "    plt.imshow(data, vmin = 0, vmax = 10, cmap = 'Greys_r');\n",
    "    file = None\n",
    "\n",
    "# USAGE: plotRadiance(glob.glob('path to file full of rasters', 'province', createDateRange('MM/DD/YYYY', 'MM/DD/YYYY')))\n",
    "# The third argument is optional. If left blank, plotRadiance will plot all the files in the folder passed to it in the first argument. This means default range is about 10 years.\n",
    "\n",
    "def plotRadiance(raster_names, province, date_range=[]):\n",
    "    rasters = []\n",
    "\n",
    "    if len(date_range) > 0:\n",
    "        for name in raster_names:\n",
    "            if any(ele in name for ele in date_range):\n",
    "                rasters.append(name)\n",
    "    else:\n",
    "        rasters = raster_names    \n",
    "\n",
    "    rasters.sort()\n",
    "    valid_rasters = []\n",
    "    result_points = []\n",
    "    x_labels = []\n",
    "    \n",
    "    for raster in rasters:\n",
    "        \n",
    "        raster_data = np.array(createRasterData(raster)).flatten()\n",
    "        raster_data[raster_data == 65535] = np.nan\n",
    "        valid_pixels = np.count_nonzero(~np.isnan(raster_data))\n",
    "\n",
    "        # Find what percentage of the masked image is valid (i.e., not negated by a bad quality flag)\n",
    "        percent = valid_pixels/calcValidPixels(province)\n",
    "        \n",
    "        # Only add rasters to list for analysis if they are 99% or more valid data\n",
    "        if (percent >= 0.80) and (np.nanmean(raster_data) < 1000):\n",
    "            mean = np.nanmean(raster_data)\n",
    "            result_points.append(mean)\n",
    "            valid_rasters.append(raster)\n",
    "       \n",
    "    for entry in valid_rasters:\n",
    "        # /Volumes/Sandisk/BlackMarble/FINAL_PYONGYANG/With Mask/A2022131.tif\n",
    "        name = entry.split('/')[6]\n",
    "        julian_date = name[1:8]\n",
    "        date = dt.datetime.strptime(julian_date, '%Y%j').strftime('%m/%d/%Y')              # Convert YYYYDDD to MM/DD/YYYY\n",
    "        # Add the rasters date as a string for later use in graph\n",
    "        x_labels.append(date)\n",
    "\n",
    "    # Create list of datetime objects for the x-axis        \n",
    "    x_datetimes = [dt.datetime.strptime(d,'%m/%d/%Y').date() for d in x_labels]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize = (20,7))\n",
    "    \n",
    "    ax.set_title(f'Radiance of {province} at night')\n",
    "    ax.set_ylabel('Radiance = ' + r'$\\left (\\frac{nW}{(cm^2)sr}\\right)$')\n",
    "    ax.set_xlabel('Date')\n",
    "    # ax.set_ylim([0, max(result_points) + 10]) # Sets the y-axis min and max\n",
    "    \n",
    "    # First arg is the datetime objects, second is how the graph should display them\n",
    "    ax.set_xticks(x_datetimes, x_labels)\n",
    "    \n",
    "    plt.style.use('dark_background')\n",
    "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%m/%d/%Y'))\n",
    "    plt.gca().xaxis.set_major_locator(plt.LinearLocator()) # Forces even spacing of x-axis ticks\n",
    "    plt.scatter(x_datetimes, result_points)\n",
    "\n",
    "    print(province.upper())\n",
    "    min_loc = result_points.index(min(result_points))\n",
    "    print(f'The least bright day was {x_labels[min_loc]}')\n",
    "    max_loc = result_points.index(max(result_points))\n",
    "    print(f'The brightest day was {x_labels[max_loc]}' + '\\n')\n",
    "\n",
    "    plt.savefig(f'{BASE_PATH}/Charts/{province}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815304b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "    raster_data = np.array(createRasterData(f\"{BASE_PATH}output/dallas_no_mask/A2020275.tif\")).flatten()\n",
    "    raster_data[raster_data == 65535] = np.nan\n",
    "    total_pixels = np.count_nonzero(~np.isnan(raster_data))\n",
    "    return total_pixels\n",
    "\n",
    "def generate_date_list(): # Used to update global variable DATES when new files are added to the RAW working directory\n",
    "\n",
    "    result_array = []\n",
    "    \n",
    "    for file in RAW_H5:\n",
    "        title = file.split('/')[5].split('.')[1]\n",
    "        yyyyddd = title[1:8]                                          # First: product name\n",
    "        date = dt.datetime.strptime(yyyyddd, '%Y%j').strftime('%m/%d/%Y')              # Convert YYYYDDD to MM/DD/YYYY\n",
    "        result_array.append(date)\n",
    "        \n",
    "    return result_array\n",
    "\n",
    "def showTif(specific_file):\n",
    "    file = gdal.Open(specific_file)\n",
    "    band = file.GetRasterBand(1)\n",
    "    data = band.ReadAsArray().astype('float') # Import band as an array with type float\n",
    "    print(np.nanmax(data))\n",
    "    \n",
    "    plt.figure(figsize = (10,7.5))    # Set the figure size (x,y)\n",
    "    plt.axis('off')                   # Remove the axes' values\n",
    "    # Plot the array, using a colormap and setting a custom linear stretch based on the min/max EVI values\n",
    "    plt.imshow(data, vmin = 0, vmax = 10, cmap = 'Greys_r');\n",
    "    file = None\n",
    "\n",
    "# USAGE: plotRadiance(glob.glob('path to file full of rasters', 'province', createDateRange('MM/DD/YYYY', 'MM/DD/YYYY')))\n",
    "# The third argument is optional. If left blank, plotRadiance will plot all the files in the folder passed to it in the first argument. This means default range is about 10 years.\n",
    "\n",
    "def plotRadiance(raster_names, province, date_range=[]):\n",
    "    rasters = []\n",
    "\n",
    "    if len(date_range) > 0:\n",
    "        for name in raster_names:\n",
    "            if any(ele in name for ele in date_range):\n",
    "                rasters.append(name)\n",
    "    else:\n",
    "        rasters = raster_names    \n",
    "\n",
    "    rasters.sort()\n",
    "    valid_rasters = []\n",
    "    result_points = []\n",
    "    x_labels = []\n",
    "    \n",
    "    for raster in rasters:\n",
    "        \n",
    "        raster_data = np.array(createRasterData(raster)).flatten()\n",
    "        raster_data[raster_data == 65535] = np.nan\n",
    "        valid_pixels = np.count_nonzero(~np.isnan(raster_data))\n",
    "\n",
    "        # Find what percentage of the masked image is valid (i.e., not negated by a bad quality flag)\n",
    "        percent = valid_pixels/calcValidPixels(province)\n",
    "        \n",
    "        # Only add rasters to list for analysis if they are 99% or more valid data\n",
    "        if (percent >= 0.80) and (np.nanmean(raster_data) < 1000):\n",
    "            mean = np.nanmean(raster_data)\n",
    "            result_points.append(mean)\n",
    "            valid_rasters.append(raster)\n",
    "       \n",
    "    for entry in valid_rasters:\n",
    "        # /Volumes/Sandisk/BlackMarble/FINAL_PYONGYANG/With Mask/A2022131.tif\n",
    "        name = entry.split('/')[6]\n",
    "        julian_date = name[1:8]\n",
    "        date = dt.datetime.strptime(julian_date, '%Y%j').strftime('%m/%d/%Y')              # Convert YYYYDDD to MM/DD/YYYY\n",
    "        # Add the rasters date as a string for later use in graph\n",
    "        x_labels.append(date)\n",
    "\n",
    "    # Create list of datetime objects for the x-axis        \n",
    "    x_datetimes = [dt.datetime.strptime(d,'%m/%d/%Y').date() for d in x_labels]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize = (20,7))\n",
    "    \n",
    "    ax.set_title(f'Radiance of {province} at night')\n",
    "    ax.set_ylabel('Radiance = ' + r'$\\left (\\frac{nW}{(cm^2)sr}\\right)$')\n",
    "    ax.set_xlabel('Date')\n",
    "    # ax.set_ylim([0, max(result_points) + 10]) # Sets the y-axis min and max\n",
    "    \n",
    "    # First arg is the datetime objects, second is how the graph should display them\n",
    "    ax.set_xticks(x_datetimes, x_labels)\n",
    "    \n",
    "    plt.style.use('dark_background')\n",
    "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%m/%d/%Y'))\n",
    "    plt.gca().xaxis.set_major_locator(plt.LinearLocator()) # Forces even spacing of x-axis ticks\n",
    "    plt.scatter(x_datetimes, result_points)\n",
    "\n",
    "    print(province.upper())\n",
    "    min_loc = result_points.index(min(result_points))\n",
    "    print(f'The least bright day was {x_labels[min_loc]}')\n",
    "    max_loc = result_points.index(max(result_points))\n",
    "    print(f'The brightest day was {x_labels[max_loc]}' + '\\n')\n",
    "\n",
    "    plt.savefig(f'{BASE_PATH}/Charts/{province}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0b7ea6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "large_mosaics = glob.glob(f'{BASE_PATH}/Merged Tiles/**.tif')\n",
    "large_mosaics.sort()\n",
    "\n",
    "# /Volumes/Sandisk/BlackMarble/Merged Tiles\n",
    "for file in large_mosaics:\n",
    "\n",
    "    output_name = file.split('/')[5]\n",
    "\n",
    "    with fiona.open('/Users/ethanjewell/Desktop/Python Env/Scripting/Map Data/Shapefiles/Korean Peninsula/Korean Peninsula.shp') as shapefile:\n",
    "        shapes = [feature[\"geometry\"] for feature in shapefile]\n",
    "\n",
    "    with rio.open(file) as src:\n",
    "        out_image, out_transform = rio.mask.mask(src, shapes, nodata=65535, crop=True)\n",
    "        out_meta = src.meta\n",
    "        out_meta.update({\"driver\": \"GTiff\",\n",
    "                \"height\": out_image.shape[1],\n",
    "                \"width\": out_image.shape[2],\n",
    "                \"transform\": out_transform})\n",
    "\n",
    "    if 'Quality' in output_name:\n",
    "        with rio.open(f'{BASE_PATH}/DPRK Only/quality_masks/' + str(output_name), \"w\", **out_meta) as dest:\n",
    "            dest.write(out_image)\n",
    "\n",
    "    else:\n",
    "        with rio.open(f'{BASE_PATH}/DPRK Only/ntl_data/' + str(output_name), \"w\", **out_meta) as dest:\n",
    "            dest.write(out_image)\n",
    "    \n",
    "    # Delete the merged file once it has been used to generate the NTL and Quality files covering the Korean Peninsula\n",
    "    os.remove(file)\n",
    "            \n",
    "print('Initial tifs created.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0311b32-a717-4e9d-bd89-012daa940448",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
